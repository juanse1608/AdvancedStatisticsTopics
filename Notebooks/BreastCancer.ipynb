{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-Data\" data-toc-modified-id=\"Preprocessing-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preprocessing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split-Intro-Train-and-Test\" data-toc-modified-id=\"Split-Intro-Train-and-Test-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Split Intro Train and Test</a></span></li></ul></li><li><span><a href=\"#Defining-NN-Arquitecture\" data-toc-modified-id=\"Defining-NN-Arquitecture-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Defining NN Arquitecture</a></span></li><li><span><a href=\"#Training-and-Testing-NN\" data-toc-modified-id=\"Training-and-Testing-NN-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training and Testing NN</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classsification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we ran a neural network with a multilayer perceptron arquitecture in order to classify if a person does have or not breast cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:21.202644Z",
     "start_time": "2021-08-12T16:58:21.199120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF VERSION: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "print(f'TF VERSION: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:21.266868Z",
     "start_time": "2021-08-12T16:58:21.258397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read breast cancer data\n",
    "data = pd.read_csv('../Data/BreastCancer/data.csv')\n",
    "data = data.loc[:, ~data.columns.str.contains('Unnamed')]\n",
    "data.columns = data.columns.str.upper()\n",
    "data.drop(columns={'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:21.289392Z",
     "start_time": "2021-08-12T16:58:21.268594Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>RADIUS_MEAN</th>\n",
       "      <th>TEXTURE_MEAN</th>\n",
       "      <th>PERIMETER_MEAN</th>\n",
       "      <th>AREA_MEAN</th>\n",
       "      <th>SMOOTHNESS_MEAN</th>\n",
       "      <th>COMPACTNESS_MEAN</th>\n",
       "      <th>CONCAVITY_MEAN</th>\n",
       "      <th>CONCAVE POINTS_MEAN</th>\n",
       "      <th>SYMMETRY_MEAN</th>\n",
       "      <th>...</th>\n",
       "      <th>RADIUS_WORST</th>\n",
       "      <th>TEXTURE_WORST</th>\n",
       "      <th>PERIMETER_WORST</th>\n",
       "      <th>AREA_WORST</th>\n",
       "      <th>SMOOTHNESS_WORST</th>\n",
       "      <th>COMPACTNESS_WORST</th>\n",
       "      <th>CONCAVITY_WORST</th>\n",
       "      <th>CONCAVE POINTS_WORST</th>\n",
       "      <th>SYMMETRY_WORST</th>\n",
       "      <th>FRACTAL_DIMENSION_WORST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  DIAGNOSIS  RADIUS_MEAN  TEXTURE_MEAN  PERIMETER_MEAN  AREA_MEAN  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   SMOOTHNESS_MEAN  COMPACTNESS_MEAN  CONCAVITY_MEAN  CONCAVE POINTS_MEAN  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   SYMMETRY_MEAN  ...  RADIUS_WORST  TEXTURE_WORST  PERIMETER_WORST  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   AREA_WORST  SMOOTHNESS_WORST  COMPACTNESS_WORST  CONCAVITY_WORST  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   CONCAVE POINTS_WORST  SYMMETRY_WORST  FRACTAL_DIMENSION_WORST  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Intro Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:21.302525Z",
     "start_time": "2021-08-12T16:58:21.291567Z"
    }
   },
   "outputs": [],
   "source": [
    "#Â Split into train test\n",
    "x , y = data.loc[:, data.columns != ('DIAGNOSIS')], data.loc[:,'DIAGNOSIS']\n",
    "dict_str_int = {'M': 0, 'B': 1}; dict_int_str = {'M': 0, 'B': 1}\n",
    "y = y.map(dict_str_int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1608, train_size=0.75)\n",
    "\n",
    "# Standardize predictors\n",
    "s_e = StandardScaler()\n",
    "x_train_std = s_e.fit_transform(x_train)\n",
    "x_test_std = s_e.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining NN Arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:21.340541Z",
     "start_time": "2021-08-12T16:58:21.304518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network \n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(25, input_dim=x_train.shape[1], activation='relu', name='Dense_1'))\n",
    "nn_model.add(Dense(50, input_dim=x_train.shape[1], activation='relu', name='Dense_2'))\n",
    "nn_model.add(Dropout(0.5, name='Dropout_1'))\n",
    "nn_model.add(Dense(50, input_dim=x_train.shape[1], activation='relu', name='Dense_3'))\n",
    "nn_model.add(Dense(25, input_dim=x_train.shape[1], activation='relu', name='Dense_4'))\n",
    "nn_model.add(Dropout(0.5, name='Dropout_2'))\n",
    "nn_model.add(Dense(1, activation='sigmoid', name='Dense_Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:21.345753Z",
     "start_time": "2021-08-12T16:58:21.342284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_1 (Dense)              (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "Dense_4 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "Dense_Output (Dense)         (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 5,926\n",
      "Trainable params: 5,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary of nn_model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:21.355558Z",
     "start_time": "2021-08-12T16:58:21.347547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss, optimizator, metrics, etc\n",
    "nn_model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                 optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T16:58:22.189118Z",
     "start_time": "2021-08-12T16:58:21.357728Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14/14 [==============================] - 1s 11ms/step - loss: 0.6319 - accuracy: 0.6754 - val_loss: 0.4083 - val_accuracy: 0.9091\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7798 - val_loss: 0.2633 - val_accuracy: 0.9510\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8788 - val_loss: 0.1677 - val_accuracy: 0.9510\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.9139 - val_loss: 0.1232 - val_accuracy: 0.9580\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9372 - val_loss: 0.1018 - val_accuracy: 0.9650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb824e34f0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model and meanwhile print train and validation metrics\n",
    "nn_model.fit(x=x_train_std, y=y_train, batch_size=32, epochs=5, validation_data=(x_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network learns pretty well and does not overfit, reaching an approx of 96.50% of accuracy in breast cancer diagnosis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Regresion-Clasificacion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
